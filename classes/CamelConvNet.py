#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Thu Apr  4 10:19:39 2024@author: adamgreenbergthink about using similar arch as:    https://kharshit.github.io/blog/2019/02/15/autoencoder-downsampling-and-upsamplingnotes:    consider referencing https://arxiv.org/pdf/1709.03754.pdf"""import torch as tcNUM_ENC_DIM = 24class CamelEncoder(tc.nn.Module):        def __init__(self):        super().__init__()                # input shape [batch size, number of channels, vector length]        # [N, 1, 256]                ## convolution layers ##        self.layer_1 = tc.nn.Conv1d( 1, 100, kernel_size = 9)        self.activ_1 = tc.nn.LeakyReLU()        # output: [N, 100, 248]                        self.pool_1 = tc.nn.MaxPool1d(2)        # output: [N, 100, 124]                self.layer_2 = tc.nn.Conv1d(100, 50, kernel_size = 5)        self.activ_2 = tc.nn.LeakyReLU()        # output: [N, 50, 120]                self.pool_2 = tc.nn.MaxPool1d(2)        # output: [N, 50, 60]                ## linear layers ##        num_neuron = 50*60        self.flattener = lambda x: x.view(-1, num_neuron)                self.layer_4 = tc.nn.Linear(num_neuron, 1024)        self.activ_4 = tc.nn.LeakyReLU()                self.layer_5 = tc.nn.Linear(1024, 256)        self.activ_5 = tc.nn.LeakyReLU()                self.layer_6= tc.nn.Linear(256, 64)        self.activ_6 = tc.nn.LeakyReLU()                self.layer_7 = tc.nn.Linear(64, NUM_ENC_DIM)            def forward(self, features):                z = features.view( features.shape[0], 1, -1)                ## convolution layers        z = self.layer_1(z)        z = self.activ_1(z)                z = self.pool_1(z)                                z = self.layer_2(z)        z = self.activ_2(z)                z = self.pool_2(z)                ## linear layers ##        z = self.flattener(z)                        z = self.layer_4(z)        z = self.activ_4(z)                z = self.layer_5(z)        z = self.activ_5(z)        z = self.layer_6(z)        z = self.activ_6(z)                        encodings = self.layer_7(z)                return encodings        class CamelLinearDecoder(tc.nn.Module):        def __init__(self):        super().__init__()        self.layer_1 = tc.nn.Linear(NUM_ENC_DIM, 32)        self.activ_1 = tc.nn.LeakyReLU()                self.layer_2 = tc.nn.Linear(32, 48)        self.activ_2 = tc.nn.LeakyReLU()                self.layer_3 = tc.nn.Linear(48,64)          self.activ_3 = tc.nn.LeakyReLU()                self.layer_4 = tc.nn.Linear(64, 128)        self.activ_4 = tc.nn.LeakyReLU()                self.layer_5 = tc.nn.Linear(128,256)            def forward(self, latents):                z = self.layer_1(latents)        z = self.activ_1(z)                z = self.layer_2(z)        z = self.activ_2(z)                z = self.layer_3(z)        z = self.activ_3(z)        z = self.layer_4(z)        z = self.activ_4(z)                features = self.layer_5(z)                return features    class CamelDecoder(tc.nn.Module):        def __init__(self):        super().__init__()        self.layer_1 = tc.nn.ConvTranspose1d(1, 32, kernel_size = 3,                                                     stride = 2)        self.activ_1 = tc.nn.LeakyReLU()                self.layer_2 = tc.nn.ConvTranspose1d(32, 64, kernel_size = 5,                                                      stride = 3)        self.activ_2 = tc.nn.LeakyReLU()                self.layer_3 = tc.nn.ConvTranspose1d(64, 1, kernel_size = 3,                                                     stride = 2)        self.activ_3 = tc.nn.LeakyReLU()                self.layer_4 = tc.nn.Linear(299, 256)            def forward(self, latents):                z = latents.view(latents.shape[0], 1, latents.shape[1])                z = self.layer_1(z)        z = self.activ_1(z)                z = self.layer_2(z)        z = self.activ_2(z)                z = self.layer_3(z)        z = self.activ_3(z)                return self.layer_4(z.view(z.shape[0], 299))    class CamelAutoEncoder(tc.nn.Module):        def __init__(self):        super().__init__()                self.encoder = CamelEncoder()        self.decoder = CamelDecoder()            def forward(self, features):        encodings = self.encoder( features)        return self.decoder(encodings), encodings    