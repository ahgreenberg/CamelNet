#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Thu Apr  4 10:19:39 2024@author: adamgreenbergthink about using similar arch as:    https://kharshit.github.io/blog/2019/02/15/autoencoder-downsampling-and-upsamplingnotes:    try making decoder2, use upsampling etc    try referencing https://arxiv.org/pdf/1709.03754.pdf    add a regularizer (perhaps L1 norm?)    try normalizing input vectors by dividing by maximum    try removing the shifting bit and doing that separately        seems that 24 might be too many    try 16 next?"""import torch as tcimport CamelData as cdimport numpy as npNUM_ENC_DIM = 24class CamelEncoder(tc.nn.Module):        def __init__(self):        super().__init__()                # [N, 1, 256]                self.layer_1 = tc.nn.Conv1d( 1, 100, kernel_size = 9)        self.activ_1 = tc.nn.LeakyReLU()        # [N, 100, 248]                        self.pool_1 = tc.nn.MaxPool1d(2)        # [N, 100, 124]                self.layer_2 = tc.nn.Conv1d(100, 50, kernel_size = 5)        self.activ_2 = tc.nn.LeakyReLU()        # [N, 50, 120]                self.pool_2 = tc.nn.MaxPool1d(2)        # [N, 50, 60]                num_neuron = 50*60        self.flattener = lambda x: x.view(-1, num_neuron)        # [N, 1950]                self.layer_4 = tc.nn.Linear(num_neuron, 1024)        self.activ_4 = tc.nn.LeakyReLU()                self.layer_5 = tc.nn.Linear(1024, 256)        self.activ_5 = tc.nn.LeakyReLU()                self.layer_6= tc.nn.Linear(256, 64)        self.activ_6 = tc.nn.LeakyReLU()                self.layer_7 = tc.nn.Linear(64, NUM_ENC_DIM)            def forward(self, features):                z = features.view( features.shape[0], 1, -1)                z = self.layer_1(z)        z = self.activ_1(z)                z = self.pool_1(z)                                z = self.layer_2(z)        z = self.activ_2(z)                z = self.pool_2(z)                z = self.flattener(z)                        z = self.layer_4(z)        z = self.activ_4(z)                z = self.layer_5(z)        z = self.activ_5(z)        z = self.layer_6(z)        z = self.activ_6(z)                        latents = self.layer_7(z)                return latents        class CamelDecoder(tc.nn.Module):        def __init__(self):        super().__init__()        self.layer_1 = tc.nn.Linear(NUM_ENC_DIM, 32)        self.activ_1 = tc.nn.LeakyReLU()                self.layer_2 = tc.nn.Linear(32, 48)        self.activ_2 = tc.nn.LeakyReLU()                self.layer_3 = tc.nn.Linear(48,64)          self.activ_3 = tc.nn.LeakyReLU()                self.layer_4 = tc.nn.Linear(64, 128)        self.activ_4 = tc.nn.LeakyReLU()                self.layer_5 = tc.nn.Linear(128,256)            def forward(self, latents):                z = self.layer_1(latents)        z = self.activ_1(z)                z = self.layer_2(z)        z = self.activ_2(z)                z = self.layer_3(z)        z = self.activ_3(z)        z = self.layer_4(z)        z = self.activ_4(z)                features = self.layer_5(z)                return features    class CamelDecoder2(tc.nn.Module):        def __init__(self):        super().__init__()        self.layer_1 = tc.nn.ConvTranspose1d(1, 32, kernel_size = 3, stride = 2)        self.activ_1 = tc.nn.LeakyReLU()                self.layer_2 = tc.nn.ConvTranspose1d(32, 64, kernel_size = 5, stride = 3)        self.activ_2 = tc.nn.LeakyReLU()                self.layer_3 = tc.nn.ConvTranspose1d(64, 1, kernel_size = 3, stride = 2)        self.activ_3 = tc.nn.LeakyReLU()                self.layer_4 = tc.nn.Linear(299, 256)            def forward(self, latents):                z = latents.view(latents.shape[0], 1, latents.shape[1])                z = self.layer_1(z)        z = self.activ_1(z)                z = self.layer_2(z)        z = self.activ_2(z)                z = self.layer_3(z)        z = self.activ_3(z)                return self.layer_4(z.view(z.shape[0], 299))    class CamelAutoEncoder(tc.nn.Module):        def __init__(self):        super().__init__()                self.encoder = CamelEncoder()        self.decoder = CamelDecoder()            def forward(self, features):                encodings = self.encoder( features)        return self.decoder( encodings ), encodingsdef recon_loss_fun(truth, reconstructed, encodings, num_fold):    # consider using torch.nn.PoissonNLLLoss        loss_mse = tc.nn.MSELoss(reduction = 'sum')(truth, reconstructed)                loss_contractive = 0    if num_fold>1:        num_ind = int(encodings.shape[0]/num_fold)        encodings_cube = encodings.view(num_ind,num_fold,NUM_ENC_DIM)                stds = tc.std(encodings_cube, dim=1)        means = tc.mean(encodings_cube, dim=1)                        loss_contractive = tc.min( (stds/means)**2 )        return loss_mse, loss_contractivedef train(state_file = None, num_epoch = 16):        ae = CamelAutoEncoder()    if state_file is not None:         ae.load_state_dict( tc.load(state_file) )        data_train = None    loss_curves = None    if num_epoch:        data_train = cd.CamelDataset( *cd.generate_camels( num_camel = 4096,                                                            locations_per_camel = 4) )         data_loader = tc.utils.data.DataLoader( data_train, batch_size = 64, shuffle = False)                assert(not data_loader.batch_size % data_train.locations_per_camel)                optimizer = tc.optim.Adam( ae.parameters(), lr = 3E-4 )        loss_fun = recon_loss_fun                lam = 1E4                loss_curves = np.zeros([num_epoch, 2])                ae.train()        for i in range(num_epoch):                                        for features_clean,features_corrupt in data_loader:                                optimizer.zero_grad()                                features_recon, encodings = ae(features_corrupt)                loss_base, loss_reg = loss_fun(features_clean,                                                   features_recon,                                                   encodings,                                                   data_train.locations_per_camel)                                loss = loss_base + lam*loss_reg                                loss.backward()                optimizer.step()                                loss_curves[i,0] += loss_base                loss_curves[i,1] += lam*loss_reg                            loss_curves[i,:] /= len(data_train)            print(f"iteration: {i}, loss: {loss_curves[i,0]:.3f}, {loss_curves[i,1]:.3f}")            ae.eval()        return ae, data_train, loss_curves